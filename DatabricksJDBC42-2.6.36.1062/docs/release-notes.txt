==============================================================================
Databricks JDBC Driver Release Notes 
==============================================================================

The release notes provide details of enhancements, features, known issues, and
workflow changes in Databricks JDBC Driver 2.6.36, as well as the version 
history. 


2.6.36 =======================================================================

Released 2023-10-18

Enhancements & New Features

 * [SPARKJ-720] Token cache support

   The driver now supports disabling the refresh token cache. To do this, 
   set the EnableTokenCache property to 0. The TokenCachePassPhrase property
   needs to be set to a passphrase when using token cache. For more 
   information, see the Installation and Configuration Guide.


Resolved Issues
The following issue has been resolved in Databricks JDBC Driver 2.6.36.

 * [SPARKJ-720] The driver had issues with the OAuth token cache expiring. 
 
 * [SPARKJ-724] Package org.apache.commons.lang does not exist issue.
 
 * [SPARKJ-725] JDBC Driver throws exception if the string length of HOST is
   less than 20 when using OAuth.


Known Issues 
The following are known issues that you may encounter due to limitations in 
the data source, the driver or an application. 

 * [SPARKJ-654] In some cases, when using IBM JRE and the Arrow result set 
   serialization feature, the driver handles the Unicode characters 
   incorrectly.
 
   As a workaround, set the EnableArrow property to 0 in the connection  
   string.

 * [SPARKJ-573] Issue when deserializing Apache Arrow data with Java JVMs 
   version 11 or higher, due to compatibility issues. 
   
   As a workaround, if you encounter the "Error occurred while deserializing 
   arrow data: sun.misc.Unsafe or java.nio.DirectByteBuffer.<init>(long, int) 
   not available" error, add the follwing line:
   
   --add-opens java.base/java.nio=ALL-UNNAMED

   For more information, see the Installation and Configuration Guide.

 * [SPARKJ-330] Issue with date and timestamp before the beginning of the 
   Gregorian calendar when connecting to Spark 2.4.4 or later, or versions 
   previous to 3.0, with Arrow result set serialization.
 
   When using Spark 2.4.4 or later, or versions previous to Spark 3.0, DATE 
   and TIMESTAMP data before October 15, 1582 may be returned incorrectly if 
   the server supports serializing query results using Apache Arrow. This 
   issue should not impact most distributions of Apache Spark.

   To confirm if your distribution of Spark 2.4.4 or later has been impacted 
   by this issue, you can execute the following query:

   SELECT DATE '1581-10-14'

   If the result returned by the connector is 1581-10-24, then you are 
   impacted by the issue. In this case, if your data set contains date and/or
   timestamp data earlier than October 15, 1582, you can work around this 
   issue by adding EnableArrow=0 in your connection URL to disable the Arrow
   result set serialization feature. 

 * [SPARKJ-267] The JDBC 4.0 version of the connector fails to connect to 
   servers that require encryption using TLS 1.1 or later.

   When you attempt to connect to the server, the connection fails and the
   connector returns an SSL handshake exception. This issue occurs only when
   you run the connector using Java Runtime Environment (JRE) 6.0. 

   As a workaround, run the connector using JRE 7.0 or 8.0.

 * When retrieving data from a BINARY column, a ClassCastException error 
   occurs.

   In Spark 1.6.3 or earlier, the server sometimes returns a 
   ClassCastException error when attempting to retrieve data from a BINARY 
   column.

   This issue is fixed as of Spark 2.0.0.

   For more information, see the JIRA issue posted by Apache named "When
   column type is binary, select occurs ClassCastException in Beeline" at
   https://issues.apache.org/jira/browse/SPARK-12143.


Workflow Changes =============================================================

The following changes may disrupt established workflows for the connector. 


2.6.33 -----------------------------------------------------------------------

 * [SPARKJ-646] Removed support for Java 7.0

   Beginning with this release, the driver no longer supports Java 7.0. For 
   a list of supported JDBC versions, see the Installation and Configuration 
   Guide.


2.6.29 -----------------------------------------------------------------------

 * [SPARKJ-618] Renamed jar files

   Beginning with this release, the following files have been renamed:
   - SparkJDBC41.jar is now DatabricksJDBC41.jar
   - SparkJDBC42.jar is now DatabricksJDBC42.jar


2.6.21 -----------------------------------------------------------------------

 * [SPARKJ-534] Renamed connection properties

   Beginning with this release, the following connection properties have been 
   renamed:
   - ClusterAutostartRetry is now TemporarilyUnavailableRetry
   - ClusterAutostartRetryTimeout is now TemporarilyUnavailableRetryTimeout


2.6.20 -----------------------------------------------------------------------

 * [SPARKJ-474] Updated catalog support 

   When connecting to a server that supports multiple catalogs, the connector
   no longer reports the catalog for schemas and tables as SPARK. Instead, the
   catalog is the one reported by the Spark server. For more information, see
   the Installation and Configuration Guide.
   
   
2.6.19 -----------------------------------------------------------------------

 * [SPARKJ-483] Removed third-party libraries

   Beginning with this release, the connector no longer includes the ZooKeeper
   and Jute libraries in the JAR file. 


2.6.18 -----------------------------------------------------------------------

 * [SPARKJ-296][SPARKJ-297] Removed support for 2.1

   Beginning with this release, the connector no longer supports servers that
   run Spark version 2.1. For information about the supported Spark versions,
   see the Installation and Configuration Guide.

 * [SPARKJ-288][SPARKJ-289] Removed support for JDBC 4.0 (Java 6)

   Beginning with this release, the connector no longer supports JDBC 4.0 
   (Java 6). For a list of supported JDBC versions, see the Installation and
   Configuration Guide.


2.6.11 -----------------------------------------------------------------------

 * [SPARKJ-301] Removed support for Spark 1.5.2 and earlier, as well as 2.0

   Beginning with this release, the driver no longer supports servers that run
   any of the following Spark versions:
   - Versions 1.5.2 and earlier
   - Version 2.0

   For information about the supported Spark versions, see the Installation 
   and Configuration Guide.

 * [SPARKJ-296][SPARKJ-298] Deprecated support for Spark 1.6 and 2.1

   Beginning with this release, support for Spark versions 1.6 and 2.1 has
   been deprecated. For information about the supported Spark versions, 
   see the Installation and Configuration Guide.

 * [SPARKJ-288] Deprecated support for JDBC 4.0 (Java 6)
 
   Beginning with this release, support for JDBC 4.0 (Java 6) has been
   deprecated. Support will be removed in a future release. For a list of
   supported JDBC versions, see the Installation and Configuration Guide.


Version History ==============================================================

2.6.35 -----------------------------------------------------------------------

Released 2023-09-19

Enhancements & New Features

 * [SPARKJ-634] OAuth 2.0 M2M based authentication support

   The connector now supports M2M based OAuth 2.0 authentication. To do this, 
   set the Auth_Flow property to 1. For more information, see the Installation
   and Configuration Guide.

 * [SPARKJ-640] Server side encryption support

   The connector now supports server side encryption with user provided keys.

 * [SPARKJ-634] OAuth 2.0 browser based authentication support

   The connector now supports browser based OAuth 2.0 authentication. To do 
   this, set the Auth_Flow property to 2. For more information, see the 
   Installation and Configuration Guide.

 * [SPARKJ-634] OAuthWebServerTimeout support

   The connector now waits for the browser response during OAuth 2.0 
   authentication before timing out. For more information, see the 
   Installation and Configuration Guide. 

* [SPARKJ-703] Improved security feature

   The connector has been updated with improved security feature for 
   connection properties to prevent SSRF attacks.
 

Resolved Issues
The following issue has been resolved in Databricks JDBC Driver 2.6.35.

 * [SPARKJ-688] The connector turns on the socket timeout by default for HTTP
   connections and provides default values.


2.6.34 -----------------------------------------------------------------------

Released 2023-06-30

Enhancements & New Features

 * [SPARKJ-661][SPARKJ-693] Updated third-party library

   The connector has been upgraded with the following third-party libraries:
   - Apache Arrow 9.0.0 (previously 7.0.0)
   - Apache HttpClient 4.5.14 (previously 4.5.13)
   - Apache HttpCore 4.4.16 (previously 4.4.14)
   - Byte Buddy 1.14.5 (previously 1.14.0) 
   - flatbuffers 23.5.26 (previously 1.12.0) 
   - Google Guava 32.0.1 (previously 31.1)
   - jackson-annotations-2.15.2 (previously 2.13.4)
   - jackson-core-2.15.2 (previously 2.13.4)
   - jackson-databind-2.15.2 (previously 2.13.4.2)
   - log4j-api 2.20.0 (previously 2.17.1)
   - log4j-core 2.20.0 (previously 2.17.1)
   - log4j-slf4j-impl 2.20.0 (previously 2.17.1)
   - lz4 1.8.0 (previously 1.7.1)
   - netty-buffer 4.1.94.Final (previously 4.1.82.Final)
   - netty-common 4.1.94.Final (previously 4.1.82.Final)
   - slf4j 1.7.36 (previously 1.7.30)
   - thrift 0.17.0 (previously 0.13.0)
   
 * [SPARKJ-680] SonarCloud scan feature

   You can now configure SonarCloud scan feature for the connector which 
   identifies and logs the expected security issues in the source code.


Resolved Issues
The following issues have been resolved in Databricks JDBC Connector 2.6.34.

 * [SPARKJ-622] The REMARKS column of the tables metadata does not populate 
   with comments. 

 * [SPARKJ-655] When a query fails to connect to the server, the connector 
   does not clean up the unused threads.

 * [SPARKJ-666] The connector shows the SQLState and the error messages
   incorrectly.

 * [SPARKJ-667] When a resultset closure operation returns an error, the 
   connector does not clean up the operation handle entries from the heartbeat
   thread.

 * [SPARKJ-676] The connector checks the server protocol version incorrectly.


2.6.33 -----------------------------------------------------------------------

Released 2023-02-10

Enhancements & New Features

 * [SPARKJ-585] SQLPrimaryKeys and SQLForeignKeys support

   The driver now supports SQLPrimaryKeys and SQLForeignKeys catalog 
   functions when connecting to a server of a supported version.


2.6.32 -----------------------------------------------------------------------

Released 2022-11-04
 
Resolved Issues
The following issues have been resolved in Databricks JDBC Driver 2.6.32.

 * [SPARKJ-627] When using cloud fetch, the driver does not clean up certain
   resources properly.

 * [SPARKJ-631] When libcurl logging is enabled, the driver leaks the URLs of
   cloud fetch results.

 * [SPARKJ-632] The credentials leaked by the driver are passed into error 
   messages. 


============================================================================== 
